{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c031f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import librosa\n",
    "import soundfile\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eadc25ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]/tmp/ipykernel_3441/340611744.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=16000, mono=False)\n",
      "/home/kobot/anaconda3/envs/sys/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 12%|█████▋                                       | 1/8 [00:13<01:36, 13.79s/it]/tmp/ipykernel_3441/340611744.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=16000, mono=False)\n",
      "/home/kobot/anaconda3/envs/sys/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 25%|███████████▎                                 | 2/8 [00:26<01:18, 13.10s/it]/tmp/ipykernel_3441/340611744.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=16000, mono=False)\n",
      "/home/kobot/anaconda3/envs/sys/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 38%|████████████████▉                            | 3/8 [00:37<01:01, 12.29s/it]/tmp/ipykernel_3441/340611744.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=16000, mono=False)\n",
      "/home/kobot/anaconda3/envs/sys/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 50%|██████████████████████▌                      | 4/8 [00:50<00:50, 12.53s/it]/tmp/ipykernel_3441/340611744.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=16000, mono=False)\n",
      "/home/kobot/anaconda3/envs/sys/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 62%|████████████████████████████▏                | 5/8 [01:03<00:37, 12.60s/it]/tmp/ipykernel_3441/340611744.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=16000, mono=False)\n",
      "/home/kobot/anaconda3/envs/sys/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 75%|█████████████████████████████████▊           | 6/8 [01:16<00:25, 12.66s/it]/tmp/ipykernel_3441/340611744.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=16000, mono=False)\n",
      "/home/kobot/anaconda3/envs/sys/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      " 88%|███████████████████████████████████████▍     | 7/8 [01:28<00:12, 12.62s/it]/tmp/ipykernel_3441/340611744.py:13: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  y, sr = librosa.load(file_path, sr=16000, mono=False)\n",
      "/home/kobot/anaconda3/envs/sys/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "100%|█████████████████████████████████████████████| 8/8 [01:41<00:00, 12.65s/it]\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 경로\n",
    "input_data_dir = \"./original\"\n",
    "output_data_dir = \"./splitted\"\n",
    "\n",
    "def preprocess_all_wav_files(directory, output_directory, duration=1.0):\n",
    "    for file_name in tqdm(os.listdir(directory)):\n",
    "        if file_name.endswith('.m4a'):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            preprocess_and_split_wav(file_path, output_directory, duration)\n",
    "\n",
    "# 데이터 전처리 및 분할\n",
    "def preprocess_and_split_wav(file_path, output_dir, duration=1.0):\n",
    "    y, sr = librosa.load(file_path, sr=16000, mono=False)\n",
    "    y = y[:, 160000:16000 * 60 * 32]\n",
    "    total_samples = len(y[0])\n",
    "    num_segments = int(np.ceil(total_samples / sr / duration))\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start = int(i * sr * duration)\n",
    "        end = int(min((i + 1) * sr * duration, total_samples))\n",
    "       \n",
    "        segment0 = y[0][start:end]\n",
    "        if len(segment0) < sr * duration:\n",
    "            padding = np.zeros(int(sr * duration - len(segment0)))  # 수정된 부분\n",
    "            segment0 = np.concatenate((segment0, padding))\n",
    "        \n",
    "        segment1 = y[1][start:end]\n",
    "        if len(segment1) < sr * duration:\n",
    "            padding = np.zeros(int(sr * duration - len(segment1)))  # 수정된 부분\n",
    "            segment1 = np.concatenate((segment1, padding))\n",
    "           \n",
    "        output_file = os.path.join(output_dir, f\"{os.path.splitext(os.path.basename(file_path))[0]}_{i}.wav\")\n",
    "        soundfile.write(output_file, np.swapaxes(np.array([segment0, segment1]), 0, 1), sr)\n",
    "\n",
    "# 모든 wav 파일에 대해 전처리 수행\n",
    "preprocess_all_wav_files(input_data_dir, output_data_dir, duration=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a25a31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T11:00:02.025880Z",
     "iopub.status.busy": "2023-09-04T11:00:02.025623Z",
     "iopub.status.idle": "2023-09-04T11:00:02.037327Z",
     "shell.execute_reply": "2023-09-04T11:00:02.036444Z",
     "shell.execute_reply.started": "2023-09-04T11:00:02.025861Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DirectionDataset(data.Dataset):\n",
    "    def __init__(self, rpath):\n",
    "        bg_noises = glob('./bg_noise/TUT-acoustic-scenes-2016-evaluation/audio/*.wav')\n",
    "\n",
    "        self.noise,_ = librosa.load(bg_noises[0], sr=16000)\n",
    "        for bg_noise in bg_noises[1:10]:\n",
    "            tmp, _ = librosa.load(bg_noise, sr=16000)\n",
    "            self.noise = np.concatenate((self.noise, tmp), axis=0)\n",
    "        \n",
    "        self.audio_samples = glob(f\"{rpath}/*.wav\")\n",
    "        self.label_map = {\n",
    "            'left':0,\n",
    "            'front':1,\n",
    "            'right':2,\n",
    "            'back':3,\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.audio_samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        audio, sr = librosa.load(self.audio_samples[idx], sr=16000, mono=False)\n",
    "        \n",
    "        for direction in self.label_map.keys():\n",
    "            if direction in self.audio_samples[idx]:\n",
    "                label = self.label_map[direction]\n",
    "                break\n",
    "        \n",
    "        if random.random() > 0.3:\n",
    "            random_sample = int(random.random() * len(self.noise)) - sr\n",
    "            ramdom_sample = 0 if random_sample <= 0 else random_sample\n",
    "            noise = self.noise[random_sample:random_sample+sr*1]\n",
    "\n",
    "            # 원하는 SNR 설정 (예: 10 dB)\n",
    "            desired_snr_db = random.choices(range(10, 20))[0]\n",
    "\n",
    "            # SNR 계산\n",
    "            clean_power = np.mean(audio ** 2)\n",
    "            noise_power = np.mean(noise ** 2)\n",
    "            snr_db = 10 * np.log10(clean_power / noise_power)\n",
    "\n",
    "            # 배경 소음 스케일링\n",
    "            scaling_factor = 10 ** ((snr_db - desired_snr_db) / 20)\n",
    "            scaled_noise = noise * scaling_factor\n",
    "\n",
    "            # 배경 소음을 음성에 추가\n",
    "            try:\n",
    "                audio = audio + scaled_noise\n",
    "            except:\n",
    "                audio = audio\n",
    "        \n",
    "        \n",
    "        win_length = 320 # 320은 20ms 의미\n",
    "        \n",
    "        stft1 = librosa.stft(audio[0], n_fft=512, hop_length=win_length, win_length=win_length)\n",
    "        stft2 = librosa.stft(audio[1], n_fft=512, hop_length=win_length, win_length=win_length)\n",
    "        \n",
    "        feature_set1 = torch.tensor(np.concatenate((stft1.real, stft2.real), axis=0))\n",
    "        feature_set2 = torch.tensor(np.concatenate((stft1.imag, stft2.imag), axis=0))\n",
    "        \n",
    "        feature = torch.concatenate((feature_set1, feature_set2), axis=0)\n",
    "        \n",
    "        return feature.unsqueeze(0).to('cuda'), torch.tensor(label).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a3fa083-942b-4886-bffa-a988566cd232",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T11:00:34.866362Z",
     "iopub.status.busy": "2023-09-04T11:00:34.865979Z",
     "iopub.status.idle": "2023-09-04T11:00:35.688653Z",
     "shell.execute_reply": "2023-09-04T11:00:35.688135Z",
     "shell.execute_reply.started": "2023-09-04T11:00:34.866332Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = DirectionDataset('./splitted')\n",
    "train_loader = data.DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f53e057d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0, device='cuda:0'), './splitted/left_concat2_810.wav')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 4500\n",
    "dataset.__getitem__(idx)[1], dataset.audio_samples[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6b1d6f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T11:00:35.691640Z",
     "iopub.status.busy": "2023-09-04T11:00:35.690707Z",
     "iopub.status.idle": "2023-09-04T11:00:35.697504Z",
     "shell.execute_reply": "2023-09-04T11:00:35.696933Z",
     "shell.execute_reply.started": "2023-09-04T11:00:35.691617Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DOAModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DOAModel, self).__init__()\n",
    "        self.CNNLayer = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, (2,2), stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2,2)),\n",
    "            \n",
    "            nn.Conv2d(64, 64, (2,2), stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(64, 64, (2,2), stride=(2,2)),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.LinearLayer = nn.Sequential(\n",
    "            nn.Linear(12288, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(256, 4),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        conv_output = self.CNNLayer(x)\n",
    "        flatten = self.flatten(conv_output)\n",
    "        linear_output = self.LinearLayer(flatten)\n",
    "        \n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5df5769f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T11:29:21.554436Z",
     "iopub.status.busy": "2023-09-04T11:29:21.554171Z",
     "iopub.status.idle": "2023-09-04T11:29:21.678444Z",
     "shell.execute_reply": "2023-09-04T11:29:21.677935Z",
     "shell.execute_reply.started": "2023-09-04T11:29:21.554417Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2390, 0.2482, 0.2569, 0.2559]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DOAModel().to('cuda')\n",
    "model.forward(torch.randn((1, 1, 1028, 51)).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d3daa7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T11:29:56.263632Z",
     "iopub.status.busy": "2023-09-04T11:29:56.263380Z",
     "iopub.status.idle": "2023-09-04T11:38:23.756260Z",
     "shell.execute_reply": "2023-09-04T11:38:23.741910Z",
     "shell.execute_reply.started": "2023-09-04T11:29:56.263614Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.1559\n",
      "best model saved. loss :  1.1559103727340698\n",
      "Epoch [2/100], Loss: 1.0744\n",
      "best model saved. loss :  1.0743571519851685\n",
      "Epoch [3/100], Loss: 0.8516\n",
      "best model saved. loss :  0.8515655994415283\n",
      "Epoch [4/100], Loss: 0.8583\n",
      "Epoch [5/100], Loss: 0.8163\n",
      "best model saved. loss :  0.8162583708763123\n",
      "Epoch [6/100], Loss: 0.8516\n",
      "Epoch [7/100], Loss: 0.8315\n",
      "Epoch [8/100], Loss: 0.8885\n",
      "Epoch [9/100], Loss: 0.8184\n",
      "Epoch [10/100], Loss: 0.9051\n",
      "Epoch [11/100], Loss: 0.8340\n",
      "Epoch [12/100], Loss: 0.8719\n",
      "Epoch [13/100], Loss: 0.8259\n",
      "Epoch [14/100], Loss: 0.8066\n",
      "best model saved. loss :  0.8066262602806091\n",
      "Epoch [15/100], Loss: 0.7657\n",
      "best model saved. loss :  0.7657250761985779\n",
      "Epoch [16/100], Loss: 0.8276\n",
      "Epoch [17/100], Loss: 0.7561\n",
      "best model saved. loss :  0.7560704350471497\n",
      "Epoch [18/100], Loss: 0.8082\n",
      "Epoch [19/100], Loss: 0.7614\n",
      "Epoch [20/100], Loss: 0.7665\n",
      "Epoch [21/100], Loss: 0.7771\n",
      "Epoch [22/100], Loss: 0.7719\n",
      "Epoch [23/100], Loss: 0.7660\n",
      "Epoch [24/100], Loss: 0.8394\n",
      "Epoch [25/100], Loss: 0.7853\n",
      "Epoch [26/100], Loss: 0.8399\n",
      "Epoch [27/100], Loss: 0.8437\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_x, batch_y \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      9\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     10\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(batch_x)\n",
      "File \u001b[0;32m~/anaconda3/envs/sys/lib/python3.8/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/sys/lib/python3.8/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/sys/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/sys/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[2], line 38\u001b[0m, in \u001b[0;36mDirectionDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     35\u001b[0m desired_snr_db \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39mchoices(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# SNR 계산\u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m clean_power \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m noise_power \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(noise \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     40\u001b[0m snr_db \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog10(clean_power \u001b[38;5;241m/\u001b[39m noise_power)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/sys/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3461\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3462\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3465\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/sys/lib/python3.8/site-packages/numpy/core/_methods.py:181\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    178\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m mu\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf4\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    179\u001b[0m         is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _no_nep50_warning():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "big_loss = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_x, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    if loss.item() <= big_loss:\n",
    "        big_loss = loss.item()\n",
    "        torch.save(model, './best_model.pt')\n",
    "        print('best model saved. loss : ', big_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a51a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(model, './best_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "349295bf-aa6a-4f52-a5e5-bf641ec80f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-04T11:51:42.257755Z",
     "iopub.status.busy": "2023-09-04T11:51:42.257468Z",
     "iopub.status.idle": "2023-09-04T11:51:42.431177Z",
     "shell.execute_reply": "2023-09-04T11:51:42.430363Z",
     "shell.execute_reply.started": "2023-09-04T11:51:42.257734Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4754/1475642842.py:1: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load('./┐╖2.m4a', sr=16000, mono=False)\n",
      "/home/kobot/anaconda3/envs/sys/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[9.0302e-01, 6.0750e-02, 3.6184e-02, 4.2839e-05]], device='cuda:0',\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio, sr = librosa.load('./┐╖2.m4a', sr=16000, mono=False)\n",
    "audio = audio[:, :16000]\n",
    "#audio = librosa.util.normalize(audio, axis=1, norm=2)\n",
    "\n",
    "win_length = 320 # 320은 20ms 의미\n",
    "stft1 = librosa.stft(audio[0], n_fft=512, hop_length=win_length, win_length=win_length)\n",
    "stft2 = librosa.stft(audio[1], n_fft=512, hop_length=win_length, win_length=win_length)\n",
    "\n",
    "feature_set1 = torch.tensor(np.concatenate((stft1.real, stft2.real), axis=0))\n",
    "feature_set2 = torch.tensor(np.concatenate((stft1.imag, stft2.imag), axis=0))\n",
    "        \n",
    "feature = torch.concatenate((feature_set1, feature_set2), axis=0)\n",
    "        \n",
    "feature = feature.unsqueeze(0).to('cuda')\n",
    "model.forward(feature.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fdb4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './4direction_best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbe1794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SYS",
   "language": "python",
   "name": "sys"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
